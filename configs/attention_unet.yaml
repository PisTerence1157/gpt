# Attention U-Net specific configuration

# Model specific settings
model:
  name: "attention_unet"
  in_channels: 1
  out_channels: 1
  features: [64, 128, 256, 512]
  dropout: 0.15  # 稍微增加dropout防止过拟合

# Training adjustments for Attention U-Net
training:
  batch_size: 16
  num_epochs: 40
  learning_rate: 0.001
  weight_decay: 0.0001
  
# Data augmentation for training
augmentation:
  horizontal_flip: 0.5
  rotation: 15
  scale: [0.9, 1.1]
  brightness: 0.1
  contrast: 0.1

# Scheduler
scheduler:
  type: "reduce_on_plateau"
  factor: 0.5
  patience: 3
  threshold: 0.001
  min_lr: 1e-6

# Model specific paths - 重要：不同的保存路径
paths:
  checkpoint_path: "checkpoints/attention_unet_best.pt"
  log_path: "outputs/logs/attention_unet"
  results_path: "outputs/results/attention_unet_metrics.json"

# Loss function
loss:
  type: "dice_bce"
  dice_weight: 0.7
  bce_weight: 0.3

# Metrics to track
metrics:
  - "dice"
  - "iou" 
  - "precision"
  - "recall"
  - "accuracy"

# Early stopping
early_stopping:
  patience: 6
  min_delta: 0.002
  monitor: "val_dice"
  mode: "max"

# Logging - 专门的日志目录
logging:
  log_dir: "outputs/logs/attention_unet"
  save_dir: "checkpoints/attention_unet"
  log_interval: 10

# Device settings
device: "cuda"
num_workers: 4

# Data paths
data:
  image_dir: "/Users/t/Documents/DISSERTATION/Chest-X-Ray/image"
  mask_dir: "/Users/t/Documents/DISSERTATION/Chest-X-Ray/mask"
  metadata_path: "data/metadata.csv"
  split_path: "data/split.csv"

# Dataset settings
dataset:
  image_size: [512, 512]
  normalize: true
  mean: [0.485]
  std: [0.229]

# Data split ratios
split:
  train: 0.7
  val: 0.15
  test: 0.15
  random_seed: 42
