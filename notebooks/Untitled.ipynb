{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9694ac24-1b9a-41c1-9ff2-98379539c429",
   "metadata": {},
   "source": [
    "# In-Depth Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "d188099b-8dad-40fe-9336-b88cf564a106",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/t/Documents/DISSERTATION\n"
     ]
    }
   ],
   "source": [
    "%cd ~/Documents/DISSERTATION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc791f9e-d84a-4257-8494-632107b8f974",
   "metadata": {},
   "source": [
    "## Rigorous paired significance testing and confidence intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a56faabe-1bf2-4904-84f5-c96c49072baa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 246 samples for train split\n",
      "Loaded 246 samples for val split\n",
      "Loaded 212 samples for test split\n",
      "Loaded 246 samples for train split\n",
      "Loaded 246 samples for val split\n",
      "Loaded 212 samples for test split\n",
      "[Dice] Δmean = 0.002237, 95% CI [0.001729, 0.002747]\n",
      "  paired t-test: t = 8.553, p = 0.0000\n",
      "  Wilcoxon (H1: Attention > U-Net): p = 0.0000\n",
      "  Permutation p ≈ 0.0000\n",
      "  Effect size (Cohen's dz) = 8.553\n",
      "[IoU ] Δmean = 0.004199 (std = 0.006921, n = 212)\n"
     ]
    }
   ],
   "source": [
    "# Rigorous paired significance testing and confidence intervals\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import inspect\n",
    "import numpy as np\n",
    "import torch\n",
    "import yaml\n",
    "from collections import OrderedDict\n",
    "from scipy import stats\n",
    "\n",
    "\n",
    "PROJECT_ROOT = os.getcwd()\n",
    "if PROJECT_ROOT not in sys.path:\n",
    "    sys.path.insert(0, PROJECT_ROOT)\n",
    "\n",
    "# Project modules\n",
    "from datasets import create_data_loaders\n",
    "from utils.metrics import dice_coefficient, iou_score\n",
    "from models.unet import UNet\n",
    "from models.attention_unet import AttentionUNet\n",
    "\n",
    "\n",
    "def build_test_loader(cfg_path: str):\n",
    "    \"\"\"Read config; enforce a deterministic test_loader order and disable multiprocessing (num_workers=0).\"\"\"\n",
    "    with open(cfg_path, \"r\") as f:\n",
    "        cfg = yaml.safe_load(f)\n",
    "    cfg = cfg or {}\n",
    "\n",
    "    # — Disable multiprocessing to avoid failures when spawning child processes — #\n",
    "    cfg.setdefault(\"data\", {})\n",
    "    cfg[\"data\"][\"shuffle\"] = False\n",
    "    cfg[\"data\"][\"num_workers\"] = 0\n",
    "    cfg[\"data\"][\"pin_memory\"] = False       # Avoid pin_memory issues on Mac/CPU\n",
    "    cfg[\"data\"][\"persistent_workers\"] = False\n",
    "\n",
    "    cfg.setdefault(\"training\", {})\n",
    "    cfg[\"training\"][\"num_workers\"] = 0\n",
    "    cfg[\"training\"][\"pin_memory\"] = False\n",
    "    cfg[\"training\"][\"persistent_workers\"] = False\n",
    "\n",
    "    _, _, test_loader, _ = create_data_loaders(cfg)\n",
    "    return cfg, test_loader\n",
    "\n",
    "\n",
    "def _filter_kwargs_for_ctor(model_cls, maybe_kwargs: dict):\n",
    "    sig = inspect.signature(model_cls.__init__)\n",
    "    return {k: v for k, v in (maybe_kwargs or {}).items() if k in sig.parameters}\n",
    "\n",
    "\n",
    "def load_model(model_cls, cfg: dict, ckpt_path: str, device: str = \"cpu\"):\n",
    "    ctor_kwargs = _filter_kwargs_for_ctor(model_cls, cfg.get(\"model\", {}))\n",
    "    model = model_cls(**ctor_kwargs).to(device)\n",
    "\n",
    "    # Explicitly disable \"weights-only\" safe mode (PyTorch 2.6+ defaults to weights_only=True)\n",
    "    ckpt = torch.load(ckpt_path, map_location=device, weights_only=False)\n",
    "\n",
    "    # Handle different checkpoint formats\n",
    "    if isinstance(ckpt, dict) and \"model_state_dict\" in ckpt:\n",
    "        state = ckpt[\"model_state_dict\"]\n",
    "    elif isinstance(ckpt, dict) and \"state_dict\" in ckpt:\n",
    "        state = ckpt[\"state_dict\"]\n",
    "    else:\n",
    "        state = ckpt\n",
    "\n",
    "    # Remove \"module.\" prefix if the checkpoint was saved with DataParallel/DistributedDataParallel\n",
    "    new_state = OrderedDict()\n",
    "    for k, v in state.items():\n",
    "        if k.startswith(\"module.\"):\n",
    "            new_state[k[len(\"module.\"):]] = v\n",
    "        else:\n",
    "            new_state[k] = v\n",
    "\n",
    "    model.load_state_dict(new_state, strict=True)\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "\n",
    "def paired_metrics(unet_ckpt: str,\n",
    "                   attn_ckpt: str,\n",
    "                   unet_cfg: str,\n",
    "                   attn_cfg: str,\n",
    "                   threshold: float = 0.5,\n",
    "                   device: str = \"cpu\"):\n",
    "    \"\"\"Under identical test-set ordering, compute per-sample Dice/IoU for both models and return paired arrays.\"\"\"\n",
    "    cfg_u, test_loader = build_test_loader(unet_cfg)\n",
    "    cfg_a, _ = build_test_loader(attn_cfg)  # Only to obtain Attention U-Net ctor args; test order follows the first loader\n",
    "\n",
    "    m_u = load_model(UNet, cfg_u, unet_ckpt, device)\n",
    "    m_a = load_model(AttentionUNet, cfg_a, attn_ckpt, device)\n",
    "\n",
    "    dice_u, dice_a, iou_u, iou_a = [], [], [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            x = batch[\"image\"].to(device)\n",
    "            y = batch[\"mask\"].to(device)\n",
    "\n",
    "            # Forward pass + sigmoid to probability\n",
    "            pu = torch.sigmoid(m_u(x)).cpu().numpy()\n",
    "            pa = torch.sigmoid(m_a(x)).cpu().numpy()\n",
    "            y_ = y.cpu().numpy()\n",
    "\n",
    "            B = x.size(0)\n",
    "            for i in range(B):\n",
    "                # Binarize using threshold\n",
    "                dice_u.append(dice_coefficient(pu[i:i+1], y_[i:i+1], threshold=threshold))\n",
    "                dice_a.append(dice_coefficient(pa[i:i+1], y_[i:i+1], threshold=threshold))\n",
    "                iou_u.append(iou_score(pu[i:i+1], y_[i:i+1], threshold=threshold))\n",
    "                iou_a.append(iou_score(pa[i:i+1], y_[i:i+1], threshold=threshold))\n",
    "\n",
    "    return (np.array(dice_u), np.array(dice_a)), (np.array(iou_u), np.array(iou_a))\n",
    "\n",
    "\n",
    "def bootstrap_CI(diff: np.ndarray, B: int = 10000, seed: int = 0):\n",
    "    \"\"\"Percentile bootstrap CI for the mean of paired differences.\"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "    boot = rng.choice(diff, size=(B, diff.size), replace=True).mean(axis=1)\n",
    "    return np.percentile(boot, [2.5, 97.5])\n",
    "\n",
    "\n",
    "def permutation_pvalue(diff: np.ndarray, B: int = 20000, seed: int = 0):\n",
    "    \"\"\"Sign-flip permutation test under H0: mean(diff) = 0; returns right-tailed p-value.\"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "    signs = rng.choice([-1, 1], size=(B, diff.size))\n",
    "    perm_means = (signs * diff).mean(axis=1)\n",
    "    p = ((perm_means >= diff.mean()).sum() + 1) / (B + 1)\n",
    "    return p\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    UNET_CFG = \"configs/unet.yaml\"\n",
    "    ATTN_CFG = \"configs/attention_unet.yaml\"\n",
    "    UNET_CKPT = \"checkpoints/unet/best_model.pt\"\n",
    "    ATTN_CKPT = \"checkpoints/attention_unet/best_model.pt\"\n",
    "\n",
    "    DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    THRESH = 0.5\n",
    "\n",
    "    # Compute per-sample metrics\n",
    "    (dice_u, dice_a), (iou_u, iou_a) = paired_metrics(\n",
    "        UNET_CKPT, ATTN_CKPT, UNET_CFG, ATTN_CFG, threshold=THRESH, device=DEVICE\n",
    "    )\n",
    "\n",
    "    # Differences\n",
    "    d_dice = dice_a - dice_u\n",
    "    d_iou = iou_a - iou_u\n",
    "\n",
    "    # Statistical tests (focus on Dice)\n",
    "    t_stat, p_t = stats.ttest_rel(dice_a, dice_u, alternative=\"two-sided\")\n",
    "    w_res = stats.wilcoxon(d_dice, zero_method=\"wilcox\", alternative=\"greater\")\n",
    "    p_perm = permutation_pvalue(d_dice, B=20000, seed=0)\n",
    "\n",
    "    # Confidence interval & effect size (paired Cohen's dz)\n",
    "    ci_low, ci_high = bootstrap_CI(d_dice, B=10000, seed=0)\n",
    "    dz = d_dice.mean() / (d_dice.std(ddof=1) / np.sqrt(d_dice.size))\n",
    "\n",
    "    # Output\n",
    "    print(f\"[Dice] Δmean = {d_dice.mean():.6f}, 95% CI [{ci_low:.6f}, {ci_high:.6f}]\")\n",
    "    print(f\"  paired t-test: t = {t_stat:.3f}, p = {p_t:.4f}\")\n",
    "    print(f\"  Wilcoxon (H1: Attention > U-Net): p = {w_res.pvalue:.4f}\")\n",
    "    print(f\"  Permutation p ≈ {p_perm:.4f}\")\n",
    "    print(f\"  Effect size (Cohen's dz) = {dz:.3f}\")\n",
    "\n",
    "    print(f\"[IoU ] Δmean = {d_iou.mean():.6f} (std = {d_iou.std(ddof=1):.6f}, n = {d_iou.size})\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57072c90-7c0d-47cd-9457-2068fdda1bd4",
   "metadata": {},
   "source": [
    "## Bucketed performance analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "44ff4f1e-d2ab-4966-8673-30ecf845d47c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 246 samples for train split\n",
      "Loaded 246 samples for val split\n",
      "Loaded 212 samples for test split\n",
      "=== ΔDice by lung area ratio bin (0 = lowest) ===\n",
      " bucket  n  delta_mean  delta_ci_low  delta_ci_high  wilcoxon_p\n",
      "      0 43    0.003597      0.002351       0.004777    0.000003\n",
      "      1 42    0.002341      0.001279       0.003334    0.000007\n",
      "      2 42    0.001969      0.000556       0.003444    0.000489\n",
      "      3 42    0.001931      0.001006       0.002932    0.000541\n",
      "      4 43    0.001340      0.000541       0.002170    0.000379\n",
      "\n",
      "=== ΔDice by area bin (0 = smallest) ===\n",
      " bucket  n  delta_mean  delta_ci_low  delta_ci_high   wilcoxon_p\n",
      "      0 71    0.001658      0.000818       0.002475 2.613209e-05\n",
      "      1 70    0.002421      0.001511       0.003263 2.687844e-07\n",
      "      2 71    0.002637      0.001713       0.003594 8.679081e-08\n"
     ]
    }
   ],
   "source": [
    "# Bucketed performance analysis (5 bins for lung area ratio + 3 bins for image size)\n",
    "import os, sys, inspect\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch, yaml\n",
    "from collections import OrderedDict\n",
    "from scipy import stats\n",
    "\n",
    "# === Add project root to sys.path (to avoid import issues in multiprocessing) ===\n",
    "PROJECT_ROOT = os.getcwd()\n",
    "if PROJECT_ROOT not in sys.path:\n",
    "    sys.path.insert(0, PROJECT_ROOT)\n",
    "\n",
    "# Internal project modules\n",
    "from datasets import create_data_loaders\n",
    "from utils.metrics import dice_coefficient, iou_score\n",
    "from models.unet import UNet\n",
    "from models.attention_unet import AttentionUNet\n",
    "\n",
    "# ----------------- Utility functions -----------------\n",
    "def load_cfg(p):\n",
    "    with open(p, \"r\") as f:\n",
    "        return yaml.safe_load(f) or {}\n",
    "\n",
    "def _filter_kwargs_for_ctor(model_cls, maybe_kwargs):\n",
    "    sig = inspect.signature(model_cls.__init__)\n",
    "    return {k: v for k, v in (maybe_kwargs or {}).items() if k in sig.parameters}\n",
    "\n",
    "def load_model(model_cls, cfg, ckpt_path, device=\"cpu\"):\n",
    "    ctor = _filter_kwargs_for_ctor(model_cls, cfg.get(\"model\", {}))\n",
    "    m = model_cls(**ctor).to(device)\n",
    "\n",
    "    # Explicitly disable weights_only\n",
    "    ckpt = torch.load(ckpt_path, map_location=device, weights_only=False)\n",
    "    if isinstance(ckpt, dict) and \"model_state_dict\" in ckpt:\n",
    "        state = ckpt[\"model_state_dict\"]\n",
    "    elif isinstance(ckpt, dict) and \"state_dict\" in ckpt:\n",
    "        state = ckpt[\"state_dict\"]\n",
    "    else:\n",
    "        state = ckpt\n",
    "\n",
    "    new_state = OrderedDict((k[len(\"module.\"):] if k.startswith(\"module.\") else k, v)\n",
    "                            for k, v in state.items())\n",
    "    m.load_state_dict(new_state, strict=True)\n",
    "    m.eval()\n",
    "    return m\n",
    "\n",
    "def build_test_loader(cfg):\n",
    "    cfg.setdefault(\"data\", {})\n",
    "    cfg[\"data\"][\"shuffle\"] = False\n",
    "    cfg[\"data\"][\"num_workers\"] = 0\n",
    "    cfg[\"data\"][\"pin_memory\"] = False\n",
    "    cfg[\"data\"][\"persistent_workers\"] = False\n",
    "    _, _, test_loader, _ = create_data_loaders(cfg)\n",
    "    return test_loader\n",
    "\n",
    "# -------- Safely extract batch-level image names --------\n",
    "def get_batch_names(batch, B, global_start_idx):\n",
    "    \"\"\"\n",
    "    Returns a list of length B; attempts to extract from keys like name / image_name / path / etc.\n",
    "    Falls back to index-based naming if unavailable.\n",
    "    \"\"\"\n",
    "    candidate_keys = [\"name\", \"image_name\", \"path\", \"image_path\", \"filename\", \"id\"]\n",
    "    for key in candidate_keys:\n",
    "        if key in batch:\n",
    "            v = batch[key]\n",
    "            if isinstance(v, (list, tuple)):\n",
    "                return [str(x) for x in v]\n",
    "            if isinstance(v, np.ndarray):\n",
    "                return [str(x) for x in v.tolist()]\n",
    "            if torch.is_tensor(v):\n",
    "                vv = v.detach().cpu().numpy().tolist()\n",
    "                if isinstance(vv, (int, float, str)):\n",
    "                    return [str(vv)] * B\n",
    "                return [str(x) for x in vv]\n",
    "            return [str(v)] * B\n",
    "    return [f\"{global_start_idx + i}\" for i in range(B)]\n",
    "\n",
    "# ----------------- Per-image evaluation -----------------\n",
    "def run_per_image_metrics(unet_cfg, attn_cfg, unet_ckpt, attn_ckpt, threshold=0.5, device=\"cpu\"):\n",
    "    cu = load_cfg(unet_cfg); ca = load_cfg(attn_cfg)\n",
    "    loader = build_test_loader(cu)  \n",
    "    mu = load_model(UNet, cu, unet_ckpt, device)\n",
    "    ma = load_model(AttentionUNet, ca, attn_ckpt, device)\n",
    "\n",
    "    rows = []\n",
    "    seen = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            x = batch[\"image\"].to(device); y = batch[\"mask\"].to(device)\n",
    "            B = x.size(0)\n",
    "            names = get_batch_names(batch, B, seen)\n",
    "            pu = torch.sigmoid(mu(x)).cpu().numpy()\n",
    "            pa = torch.sigmoid(ma(x)).cpu().numpy()\n",
    "            y_ = y.cpu().numpy()\n",
    "            for i in range(B):\n",
    "                nm = str(names[i])\n",
    "                rows.append({\n",
    "                    \"image_name\": nm,\n",
    "                    \"dice_unet\": float(dice_coefficient(pu[i:i+1], y_[i:i+1], threshold)),\n",
    "                    \"dice_attn\": float(dice_coefficient(pa[i:i+1], y_[i:i+1], threshold)),\n",
    "                    \"iou_unet\":  float(iou_score(pu[i:i+1], y_[i:i+1], threshold)),\n",
    "                    \"iou_attn\":  float(iou_score(pa[i:i+1], y_[i:i+1], threshold)),\n",
    "                })\n",
    "            seen += B\n",
    "    df = pd.DataFrame(rows)\n",
    "    df[\"delta_dice\"] = df[\"dice_attn\"] - df[\"dice_unet\"]\n",
    "    df[\"delta_iou\"]  = df[\"iou_attn\"]  - df[\"iou_unet\"]\n",
    "    df[\"row_id\"] = np.arange(len(df))\n",
    "    return df\n",
    "\n",
    "# ----------------- Attach metadata and bin -----------------\n",
    "def attach_metadata(per_image_df, metadata_path, split_path):\n",
    "    meta  = pd.read_csv(metadata_path)\n",
    "    split = pd.read_csv(split_path)\n",
    "\n",
    "    # Filter to test set only, unify keys to string\n",
    "    test_names = split.loc[split[\"split\"] == \"test\", \"image_name\"].copy().astype(str)\n",
    "    meta[\"image_name\"] = meta[\"image_name\"].astype(str)\n",
    "    per_image_df[\"image_name\"] = per_image_df[\"image_name\"].astype(str)\n",
    "\n",
    "    meta_t = meta.merge(test_names.to_frame(), on=\"image_name\", how=\"inner\")\n",
    "\n",
    "    if \"positive_ratio\" in meta_t.columns:\n",
    "        meta_t = meta_t.rename(columns={\"positive_ratio\": \"lung_area_ratio\"})\n",
    "    else:\n",
    "        raise KeyError(\"Missing 'positive_ratio' column in metadata.csv (expected lung area ratio).\")\n",
    "\n",
    "    # Area and binning\n",
    "    meta_t[\"area\"] = meta_t[\"width\"] * meta_t[\"height\"]\n",
    "    meta_t[\"lung_ratio_bin\"] = pd.qcut(meta_t[\"lung_area_ratio\"], q=5, labels=False, duplicates=\"drop\")\n",
    "    meta_t[\"area_bin\"] = pd.qcut(meta_t[\"area\"], q=3, labels=False, duplicates=\"drop\")\n",
    "\n",
    "    merged = per_image_df.merge(meta_t, on=\"image_name\", how=\"left\")\n",
    "\n",
    "    # Fallback if merge failed (e.g. >20% NaN), align by row_id\n",
    "    miss_ratio = merged[\"lung_area_ratio\"].isna().mean()\n",
    "    if miss_ratio > 0.2:\n",
    "        meta_t_seq = meta_t.reset_index(drop=True).copy()\n",
    "        meta_t_seq[\"row_id\"] = np.arange(len(meta_t_seq))\n",
    "        merged = per_image_df.merge(meta_t_seq.drop(columns=[\"image_name\"]), on=\"row_id\", how=\"left\")\n",
    "\n",
    "    return merged\n",
    "\n",
    "# ----------------- Statistical summary -----------------\n",
    "def bootstrap_ci_mean(x, B=10000, seed=42):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    boot = rng.choice(x, size=(B, len(x)), replace=True).mean(axis=1)\n",
    "    return np.percentile(boot, [2.5, 97.5])\n",
    "\n",
    "def summarize_by_bucket(df, bucket_col, metric_delta_col=\"delta_dice\"):\n",
    "    out = []\n",
    "    for b, g in df.groupby(bucket_col):\n",
    "        x = g[metric_delta_col].dropna().values\n",
    "        if len(x) == 0:\n",
    "            continue\n",
    "        ci = bootstrap_ci_mean(x)\n",
    "        w = stats.wilcoxon(x, zero_method=\"wilcox\", alternative=\"greater\")  # H1: Attention > U-Net\n",
    "        out.append({\n",
    "            \"bucket\": int(b) if isinstance(b, (int, np.integer)) else str(b),\n",
    "            \"n\": int(len(x)),\n",
    "            \"delta_mean\": float(np.mean(x)),\n",
    "            \"delta_ci_low\": float(ci[0]),\n",
    "            \"delta_ci_high\": float(ci[1]),\n",
    "            \"wilcoxon_p\": float(w.pvalue)\n",
    "        })\n",
    "    return pd.DataFrame(out).sort_values(\"bucket\")\n",
    "\n",
    "# ----------------- Entry point -----------------\n",
    "def main():\n",
    "    # Adjust paths as needed\n",
    "    UNET_CFG  = \"configs/unet.yaml\"\n",
    "    ATTN_CFG  = \"configs/attention_unet.yaml\"\n",
    "    UNET_CKPT = \"checkpoints/unet/best_model.pt\"\n",
    "    ATTN_CKPT = \"checkpoints/attention_unet/best_model.pt\"\n",
    "\n",
    "    DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    THRESH = 0.5\n",
    "\n",
    "    # Per-image metrics\n",
    "    df_img = run_per_image_metrics(UNET_CFG, ATTN_CFG, UNET_CKPT, ATTN_CKPT, threshold=THRESH, device=DEVICE)\n",
    "\n",
    "    # Attach metadata\n",
    "    with open(UNET_CFG, \"r\") as f:\n",
    "        cfg = yaml.safe_load(f)\n",
    "    meta_path  = cfg[\"data\"][\"metadata_path\"]\n",
    "    split_path = cfg[\"data\"][\"split_path\"]\n",
    "    df_all = attach_metadata(df_img, meta_path, split_path)\n",
    "\n",
    "    # Output\n",
    "    os.makedirs(\"outputs/bucket_eval\", exist_ok=True)\n",
    "    df_all.to_csv(\"outputs/bucket_eval/per_image_with_meta.csv\", index=False)\n",
    "\n",
    "    # Bucket summaries: lung area ratio (5 bins) + image size (3 bins)\n",
    "    sum_lung = summarize_by_bucket(df_all, \"lung_ratio_bin\", \"delta_dice\")\n",
    "    sum_area = summarize_by_bucket(df_all, \"area_bin\", \"delta_dice\")\n",
    "\n",
    "    sum_lung.to_csv(\"outputs/bucket_eval/summary_by_lung_ratio.csv\", index=False)\n",
    "    sum_area.to_csv(\"outputs/bucket_eval/summary_by_area.csv\", index=False)\n",
    "\n",
    "    print(\"=== ΔDice by lung area ratio bin (0 = lowest) ===\")\n",
    "    print(sum_lung.to_string(index=False))\n",
    "    print(\"\\n=== ΔDice by area bin (0 = smallest) ===\")\n",
    "    print(sum_area.to_string(index=False))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd0e87f-aed0-46a2-8159-3045254eb8ab",
   "metadata": {},
   "source": [
    "## Bucketed ΔDice bar plots with 95% CI & box plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "335e0f92-17fd-4147-bbe0-f0c006231b46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved figures to: outputs/bucket_eval/figs\n"
     ]
    }
   ],
   "source": [
    "# Bucketed ΔDice bar plots with 95% CI & box plots\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "IN_DIR  = \"outputs/bucket_eval\"\n",
    "OUT_DIR = \"outputs/bucket_eval/figs\"\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "# ---- Bin labels (Q1..Q5) ----\n",
    "def pretty_bin_labels(series, prefix=\"Bin\"):\n",
    "    # series could be int or string; sort by appearance order\n",
    "    vals = sorted(series.unique(), key=lambda x: int(x) if str(x).isdigit() else x)\n",
    "    mapping = {}\n",
    "    for i, v in enumerate(vals):\n",
    "        # If bins are integers 0..k, map to Q1..Qk; otherwise use the string directly\n",
    "        if str(v).isdigit():\n",
    "            mapping[v] = f\"Q{i+1}\"\n",
    "        else:\n",
    "            mapping[v] = str(v)\n",
    "    return series.map(mapping), [mapping[v] for v in vals]\n",
    "\n",
    "# ---- 1) Bar + 95% CI: lung area ratio (5 bins) ----\n",
    "def plot_bar_ci(csv_path, title, outfile):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    if \"bucket\" not in df.columns:\n",
    "        raise ValueError(f\"Missing 'bucket' column in {csv_path}\")\n",
    "    xlabels_series, order_labels = pretty_bin_labels(df[\"bucket\"])\n",
    "    x = np.arange(len(df))\n",
    "    y = df[\"delta_mean\"].values\n",
    "    yerr = np.vstack([y - df[\"delta_ci_low\"].values,\n",
    "                      df[\"delta_ci_high\"].values - y])\n",
    "\n",
    "    plt.figure(figsize=(6.0, 3.8), dpi=300)\n",
    "    plt.bar(x, y)\n",
    "    plt.errorbar(x, y, yerr=yerr, fmt=\"none\", capsize=3, linewidth=1)\n",
    "    plt.xticks(x, xlabels_series)\n",
    "    plt.ylabel(\"ΔDice (Attention − U-Net)\")\n",
    "    plt.title(title)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(outfile, bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "\n",
    "# ---- 2) Bar + 95% CI: image area (3 bins) ----\n",
    "def plot_bar_ci_area():\n",
    "    plot_bar_ci(\n",
    "        os.path.join(IN_DIR, \"summary_by_area.csv\"),\n",
    "        \"ΔDice by Image Area (Tertiles)\",\n",
    "        os.path.join(OUT_DIR, \"bar_ci_area.png\"),\n",
    "    )\n",
    "\n",
    "def plot_bar_ci_lung():\n",
    "    plot_bar_ci(\n",
    "        os.path.join(IN_DIR, \"summary_by_lung_ratio.csv\"),\n",
    "        \"ΔDice by Lung Area Ratio (Quintiles)\",\n",
    "        os.path.join(OUT_DIR, \"bar_ci_lung.png\"),\n",
    "    )\n",
    "\n",
    "# ---- 3) Box plot: per-bin ΔDice distribution (from per_image_with_meta.csv) ----\n",
    "def plot_box_per_bucket(per_image_csv, bucket_col, title, outfile):\n",
    "    df = pd.read_csv(per_image_csv)\n",
    "    if bucket_col not in df.columns:\n",
    "        raise ValueError(f\"Missing column in {per_image_csv}: {bucket_col}\")\n",
    "    # Keep rows that have valid bucket assignment\n",
    "    df = df[pd.notnull(df[bucket_col])]\n",
    "    # Order & x-axis labels\n",
    "    if np.issubdtype(df[bucket_col].dtype, np.number):\n",
    "        order = sorted(df[bucket_col].unique())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0878d99-0b0a-4fe6-a691-12869b55c3f9",
   "metadata": {},
   "source": [
    "## Four-layer attention overlay panel figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "fe9e69c7-6cd5-4a62-8c37-9babea39cb55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 246 samples for train split\n",
      "Loaded 246 samples for val split\n",
      "Loaded 212 samples for test split\n",
      "Saved panels & captions under: outputs/attention_panels\n"
     ]
    }
   ],
   "source": [
    "# Four-layer attention overlay panel figure\n",
    "import os, sys, inspect\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch, yaml\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from collections import OrderedDict\n",
    "\n",
    "# ===== Ensure project root is in sys.path =====\n",
    "PROJECT_ROOT = os.getcwd()\n",
    "if PROJECT_ROOT not in sys.path:\n",
    "    sys.path.insert(0, PROJECT_ROOT)\n",
    "\n",
    "from datasets import create_data_loaders\n",
    "from utils.metrics import dice_coefficient, iou_score\n",
    "from models.unet import UNet\n",
    "from models.attention_unet import AttentionUNet   \n",
    "\n",
    "# ------------------------ Configuration ------------------------ #\n",
    "UNET_CFG_DEFAULT  = \"configs/unet.yaml\"\n",
    "ATTN_CFG_DEFAULT  = \"configs/attention_unet.yaml\"\n",
    "UNET_CKPT_DEFAULT = \"checkpoints/unet/best_model.pt\"\n",
    "ATTN_CKPT_DEFAULT = \"checkpoints/attention_unet/best_model.pt\"\n",
    "\n",
    "# ------------------------ Utilities ------------------------ #\n",
    "def load_cfg(p):\n",
    "    with open(p, \"r\") as f:\n",
    "        return yaml.safe_load(f) or {}\n",
    "\n",
    "def _filter_kwargs_for_ctor(model_cls, maybe_kwargs):\n",
    "    sig = inspect.signature(model_cls.__init__)\n",
    "    return {k: v for k, v in (maybe_kwargs or {}).items() if k in sig.parameters}\n",
    "\n",
    "def strict_load(model, ckpt_path, device=\"cpu\"):\n",
    "    ckpt = torch.load(ckpt_path, map_location=device, weights_only=False)\n",
    "    sd = ckpt.get(\"model_state_dict\", ckpt.get(\"state_dict\", ckpt))\n",
    "    clean = OrderedDict((k[7:], v) if k.startswith(\"module.\") else (k, v) for k, v in sd.items())\n",
    "    missing, unexpected = model.load_state_dict(clean, strict=False)\n",
    "    if getattr(missing, \"keys\", None):  \n",
    "        missing = list(missing.keys())\n",
    "    if missing or unexpected:\n",
    "        raise RuntimeError(\n",
    "            f\"[StrictLoadError] {ckpt_path}\\n\"\n",
    "            f\"  Missing: {missing}\\n\"\n",
    "            f\"  Unexpected: {unexpected}\"\n",
    "        )\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "def load_model(model_cls, cfg, ckpt_path, device=\"cpu\"):\n",
    "    ctor = _filter_kwargs_for_ctor(model_cls, cfg.get(\"model\", {}))\n",
    "    m = model_cls(**ctor).to(device)\n",
    "    m = strict_load(m, ckpt_path, device=device)\n",
    "    return m\n",
    "\n",
    "def build_test_loader(cfg):\n",
    "    cfg.setdefault(\"data\", {})\n",
    "    cfg[\"data\"][\"shuffle\"] = False\n",
    "    cfg[\"data\"][\"num_workers\"] = 0\n",
    "    cfg[\"data\"][\"pin_memory\"] = False\n",
    "    cfg[\"data\"][\"persistent_workers\"] = False\n",
    "    _, _, test_loader, _ = create_data_loaders(cfg)\n",
    "    return test_loader\n",
    "\n",
    "# -------- Safely fetch batch names (avoid tensor truth-value ambiguity) --------\n",
    "def get_batch_names(batch, B, global_start_idx):\n",
    "    \"\"\"\n",
    "    Return a list of length B. Prefer keys: name / image_name / path / image_path / filename / id.\n",
    "    If none exist or have mismatched types, fall back to sequential indices (aligned with split[test]).\n",
    "    \"\"\"\n",
    "    candidate_keys = [\"name\", \"image_name\", \"path\", \"image_path\", \"filename\", \"id\"]\n",
    "    for key in candidate_keys:\n",
    "        if key in batch:\n",
    "            v = batch[key]\n",
    "            if isinstance(v, (list, tuple)):\n",
    "                return [str(x) for x in v]\n",
    "            if isinstance(v, np.ndarray):\n",
    "                return [str(x) for x in v.tolist()]\n",
    "            if torch.is_tensor(v):\n",
    "                vv = v.detach().cpu().numpy().tolist()\n",
    "                if isinstance(vv, (int, float, str)):\n",
    "                    return [str(vv)] * B\n",
    "                return [str(x) for x in vv]\n",
    "            return [str(v)] * B\n",
    "    return [f\"{global_start_idx + i}\" for i in range(B)]\n",
    "\n",
    "# ------------------------ Hooks: capture attention maps (no model code changes) ------------------------ #\n",
    "def _is_att_block(mod_name, mod):\n",
    "    \"\"\"Loosely identify attention blocks: name contains 'attention' and there exists a 'psi' submodule.\"\"\"\n",
    "    if \"attention\" in mod_name.lower():\n",
    "        for n, m in mod.named_modules():\n",
    "            if n.endswith(\"psi\") or n.endswith(\"psi.0\"):\n",
    "                return True\n",
    "    return False\n",
    "\n",
    "def attach_attention_hooks(att_model):\n",
    "    \"\"\"\n",
    "    Register forward hooks on the 'psi' submodules of attention blocks to capture their outputs.\n",
    "    \"\"\"\n",
    "    handles = []\n",
    "    att_model._captured_attn = []  # transient cache\n",
    "\n",
    "    def _hook(_module, _inp, out):\n",
    "        if isinstance(out, torch.Tensor):\n",
    "            t = out.detach()\n",
    "            if t.dim() == 3:  # [B,h,w] -> [B,1,h,w]\n",
    "                t = t.unsqueeze(1)\n",
    "            att_model._captured_attn.append(t)\n",
    "\n",
    "    for name, mod in att_model.named_modules():\n",
    "        if _is_att_block(name, mod):\n",
    "            # Prefer hooking on 'psi'\n",
    "            psi = None\n",
    "            for n, m in mod.named_modules():\n",
    "                if n.endswith(\"psi\") or n.endswith(\"psi.0\"):\n",
    "                    psi = m\n",
    "                    break\n",
    "            target = psi if psi is not None else mod\n",
    "            handles.append(target.register_forward_hook(_hook))\n",
    "\n",
    "    return handles\n",
    "\n",
    "def get_attention_maps(att_model, x_single):\n",
    "    \"\"\"\n",
    "    Prefer reading in-model cache `self.attention_weights`; fallback to hooks otherwise.\n",
    "    Returns list[Tensor], each ~ [1,1,h,w].\n",
    "    \"\"\"\n",
    "    # Path 1: in-model cache exists\n",
    "    maps = getattr(att_model, \"attention_weights\", None)\n",
    "    if isinstance(maps, (list, tuple)) and len(maps) > 0:\n",
    "        return maps\n",
    "\n",
    "    # Path 2: capture via hooks\n",
    "    handles = attach_attention_hooks(att_model)\n",
    "    try:\n",
    "        with torch.no_grad():\n",
    "            _ = att_model(x_single)  # trigger forward\n",
    "        captured = getattr(att_model, \"_captured_attn\", [])\n",
    "        if not captured:\n",
    "            raise RuntimeError(\n",
    "                \"Hook did not capture any attention maps. \"\n",
    "                \"Check attention block naming or consider enabling in-model caching.\"\n",
    "            )\n",
    "        # Sort by resolution (small -> large), roughly “deep -> shallow”\n",
    "        captured = sorted(captured, key=lambda t: (t.shape[-2], t.shape[-1]))\n",
    "        return captured\n",
    "    finally:\n",
    "        for h in handles:\n",
    "            h.remove()\n",
    "        if hasattr(att_model, \"_captured_attn\"):\n",
    "            delattr(att_model, \"_captured_attn\")\n",
    "\n",
    "# ------------------------ Per-image metrics & selection ------------------------ #\n",
    "def per_image_metrics_and_select(unet_cfg, attn_cfg, unet_ckpt, attn_ckpt, k=6, threshold=0.5, device=\"cpu\"):\n",
    "    cu = load_cfg(unet_cfg); ca = load_cfg(attn_cfg)\n",
    "    loader = build_test_loader(cu)  \n",
    "    mu = load_model(UNet, cu, unet_ckpt, device)\n",
    "    ma = load_model(AttentionUNet, ca, attn_ckpt, device)\n",
    "\n",
    "    rows = []\n",
    "    cache = []  # list of dict per sample\n",
    "\n",
    "    seen = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            x = batch[\"image\"].to(device)\n",
    "            y = batch[\"mask\"].to(device)\n",
    "            B = x.size(0)\n",
    "            names = get_batch_names(batch, B, seen)\n",
    "\n",
    "            pu = torch.sigmoid(mu(x))\n",
    "            pa = torch.sigmoid(ma(x))  # forward also triggers attention hooks if attached\n",
    "\n",
    "            for i in range(B):\n",
    "                xi = x[i:i+1].cpu()\n",
    "                yi = y[i:i+1].cpu()\n",
    "                pui = pu[i:i+1].cpu()\n",
    "                pai = pa[i:i+1].cpu()\n",
    "\n",
    "                dice_u = float(dice_coefficient(pui.numpy(), yi.numpy(), threshold=threshold))\n",
    "                dice_a = float(dice_coefficient(pai.numpy(), yi.numpy(), threshold=threshold))\n",
    "\n",
    "                name = str(names[i])\n",
    "                rows.append({\n",
    "                    \"image_name\": name,\n",
    "                    \"dice_unet\": dice_u,\n",
    "                    \"dice_attn\": dice_a,\n",
    "                    \"delta_dice\": dice_a - dice_u,\n",
    "                })\n",
    "                cache.append({\n",
    "                    \"image_name\": name,\n",
    "                    \"image\": xi,  # [1,1,H,W] or [1,C,H,W]\n",
    "                    \"mask\":  yi,  # [1,1,H,W]\n",
    "                })\n",
    "            seen += B\n",
    "\n",
    "    df = pd.DataFrame(rows).sort_values(\"delta_dice\", ascending=False).reset_index(drop=True)\n",
    "    topk = df.head(k)[\"image_name\"].tolist()\n",
    "    bottomk = df.tail(k)[\"image_name\"].tolist()\n",
    "    idx = {c[\"image_name\"]: c for c in cache}\n",
    "    return df, topk, bottomk, idx, mu, ma\n",
    "\n",
    "# ------------------------ Visualization helpers ------------------------ #\n",
    "def to_display_img(x_tensor):\n",
    "    \"\"\"[1,C,H,W] or [C,H,W] -> (H,W) numpy normalized to [0,1] for imshow.\"\"\"\n",
    "    x = x_tensor.squeeze().float().cpu().numpy()\n",
    "    if x.ndim == 3:  # C,H,W\n",
    "        x = x[0]     # single-channel\n",
    "    x = x - x.min()\n",
    "    if x.max() > 1e-8:\n",
    "        x = x / x.max()\n",
    "    return x\n",
    "\n",
    "def prob_to_mask(p_tensor, thr=0.5):\n",
    "    p = p_tensor.squeeze().cpu().numpy()\n",
    "    if p.ndim == 3:\n",
    "        p = p[0]\n",
    "    return (p >= thr).astype(np.uint8)\n",
    "\n",
    "def upsample_to(img_like, att_map):\n",
    "    \"\"\"Upsample attention map (1,1,h,w) -> (H,W) to align with the image; return [0,1] numpy.\"\"\"\n",
    "    am = att_map.squeeze().detach().cpu().numpy()\n",
    "    if am.ndim == 3:\n",
    "        am = am[0]\n",
    "    am = (am - am.min()) / (am.max() - am.min() + 1e-8)\n",
    "    H, W = img_like.shape[-2], img_like.shape[-1]\n",
    "    am_img = Image.fromarray((am*255).astype(\"uint8\")).resize((W, H), resample=Image.BILINEAR)\n",
    "    return np.array(am_img) / 255.0\n",
    "\n",
    "def render_panel(save_path, img, gt, pred_u, pred_a, attn_maps, title):\n",
    "    \"\"\"\n",
    "    attn_maps: list of 4 numpy arrays in [0,1], shape (H,W), already upsampled.\n",
    "    Panel columns: Image | GT | U-Net | AttU-Net | Att-1 | Att-2 | Att-3 | Att-4\n",
    "    \"\"\"\n",
    "    cols = 8\n",
    "    plt.figure(figsize=(cols*2.1, 2.6), dpi=250)\n",
    "\n",
    "    # 1 Image\n",
    "    plt.subplot(1, cols, 1); plt.imshow(img, cmap=\"gray\"); plt.axis(\"off\"); plt.title(\"Image\")\n",
    "    # 2 GT\n",
    "    plt.subplot(1, cols, 2); plt.imshow(gt, cmap=\"gray\"); plt.axis(\"off\"); plt.title(\"GT\")\n",
    "    # 3 U-Net\n",
    "    plt.subplot(1, cols, 3); plt.imshow(pred_u, cmap=\"gray\"); plt.axis(\"off\"); plt.title(\"U-Net\")\n",
    "    # 4 AttU-Net\n",
    "    plt.subplot(1, cols, 4); plt.imshow(pred_a, cmap=\"gray\"); plt.axis(\"off\"); plt.title(\"AttU-Net\")\n",
    "    # 5–8 Attention overlays\n",
    "    for i, am in enumerate(attn_maps, start=5):\n",
    "        plt.subplot(1, cols, i)\n",
    "        plt.imshow(img, cmap=\"gray\")\n",
    "        plt.imshow(am, alpha=0.45)\n",
    "        plt.axis(\"off\"); plt.title(f\"Att-{i-4}\")\n",
    "    plt.suptitle(title, y=1.02, fontsize=11)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "\n",
    "# ------------------------ Main: export panel figures & captions ------------------------ #\n",
    "def export_panels(\n",
    "    unet_cfg=UNET_CFG_DEFAULT,\n",
    "    attn_cfg=ATTN_CFG_DEFAULT,\n",
    "    unet_ckpt=UNET_CKPT_DEFAULT,\n",
    "    attn_ckpt=ATTN_CKPT_DEFAULT,\n",
    "    out_dir=\"outputs/attention_panels\",\n",
    "    k=6, threshold=0.5, device=\"cpu\"\n",
    "):\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "    df, topk, bottomk, cache_idx, mu, ma = per_image_metrics_and_select(\n",
    "        unet_cfg, attn_cfg, unet_ckpt, attn_ckpt, k=k, threshold=threshold, device=device\n",
    "    )\n",
    "    # Save full per-image results\n",
    "    df.to_csv(os.path.join(out_dir, \"per_image_dice.csv\"), index=False)\n",
    "\n",
    "    selected = [(\"top\", topk), (\"bottom\", bottomk)]\n",
    "    cap_lines = []\n",
    "\n",
    "    for tag, name_list in selected:\n",
    "        tag_dir = os.path.join(out_dir, tag)\n",
    "        os.makedirs(tag_dir, exist_ok=True)\n",
    "\n",
    "        for name in name_list:\n",
    "            item = cache_idx[name]\n",
    "            x = item[\"image\"].to(device)  # [1,1,H,W]\n",
    "            y = item[\"mask\"]\n",
    "            with torch.no_grad():\n",
    "                pu = torch.sigmoid(mu(x))\n",
    "                pa = torch.sigmoid(ma(x))  \n",
    "\n",
    "            # Read attention maps and upsample to the image size\n",
    "            att_maps = get_attention_maps(ma, x)\n",
    "            up_maps = [upsample_to(x, m) for m in att_maps]\n",
    "\n",
    "            # Numpy for display\n",
    "            img_np = to_display_img(x.cpu())\n",
    "            gt_np  = prob_to_mask(y, 0.5)      # GT is a 0/1 mask; display directly\n",
    "            un_np  = prob_to_mask(pu, threshold)\n",
    "            at_np  = prob_to_mask(pa, threshold)\n",
    "\n",
    "            # Title & export\n",
    "            row = df[df[\"image_name\"] == name].iloc[0]\n",
    "            title = f\"{name} | Dice_u={row['dice_unet']:.4f}  Dice_attn={row['dice_attn']:.4f}  Δ={row['delta_dice']:.4f}\"\n",
    "            save_path = os.path.join(tag_dir, f\"{name}.png\")\n",
    "            render_panel(save_path, img_np, gt_np, un_np, at_np, up_maps, title)\n",
    "\n",
    "            # Caption (.txt)\n",
    "            cap = (\n",
    "                f\"{tag.upper()} | {name}\\n\"\n",
    "                f\"Dice (U-Net)={row['dice_unet']:.4f}, Dice (AttU-Net)={row['dice_attn']:.4f}, Δ={row['delta_dice']:.4f}\\n\"\n",
    "                f\"Notes: Inspect attention hotspots near thin/ambiguous boundaries (apices, costophrenic angles). \"\n",
    "                f\"For failure cases, check non-lung distractors (cardiac shadow, diaphragm edges, rib artifacts).\"\n",
    "            )\n",
    "            cap_lines.append(cap)\n",
    "\n",
    "    with open(os.path.join(out_dir, \"captions.txt\"), \"w\") as f:\n",
    "        f.write(\"\\n\\n\".join(cap_lines))\n",
    "\n",
    "    print(f\"Saved panels & captions under: {out_dir}\")\n",
    "\n",
    "# ------------------------ Run ------------------------ #\n",
    "if __name__ == \"__main__\":\n",
    "    DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    THRESH = 0.5\n",
    "    TOPK = 6\n",
    "\n",
    "    export_panels(\n",
    "        unet_cfg=UNET_CFG_DEFAULT,\n",
    "        attn_cfg=ATTN_CFG_DEFAULT,\n",
    "        unet_ckpt=UNET_CKPT_DEFAULT,\n",
    "        attn_ckpt=ATTN_CKPT_DEFAULT,\n",
    "        out_dir=\"outputs/attention_panels\",\n",
    "        k=TOPK, threshold=THRESH, device=DEVICE\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "bbe00647-b517-4a26-a14b-2ff69f7779bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Stratum</th>\n",
       "      <th>Level</th>\n",
       "      <th>N</th>\n",
       "      <th>Mean ΔDice</th>\n",
       "      <th>Wilcoxon p (raw)</th>\n",
       "      <th>BH q (adj)</th>\n",
       "      <th>Bonferroni p (adj)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Image area</td>\n",
       "      <td>Q1 (small)</td>\n",
       "      <td>71</td>\n",
       "      <td>0.001658</td>\n",
       "      <td>2.613209e-05</td>\n",
       "      <td>4.181134e-05</td>\n",
       "      <td>2.090567e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Image area</td>\n",
       "      <td>Q2 (medium)</td>\n",
       "      <td>70</td>\n",
       "      <td>0.002421</td>\n",
       "      <td>2.687844e-07</td>\n",
       "      <td>1.075137e-06</td>\n",
       "      <td>2.150275e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Image area</td>\n",
       "      <td>Q3 (large)</td>\n",
       "      <td>71</td>\n",
       "      <td>0.002637</td>\n",
       "      <td>8.679081e-08</td>\n",
       "      <td>6.943265e-07</td>\n",
       "      <td>6.943265e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lung area ratio</td>\n",
       "      <td>Q1 (small lungs)</td>\n",
       "      <td>43</td>\n",
       "      <td>0.003597</td>\n",
       "      <td>2.603353e-06</td>\n",
       "      <td>6.942273e-06</td>\n",
       "      <td>2.082682e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lung area ratio</td>\n",
       "      <td>Q2</td>\n",
       "      <td>42</td>\n",
       "      <td>0.002341</td>\n",
       "      <td>6.794283e-06</td>\n",
       "      <td>1.358857e-05</td>\n",
       "      <td>5.435426e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Lung area ratio</td>\n",
       "      <td>Q3</td>\n",
       "      <td>42</td>\n",
       "      <td>0.001969</td>\n",
       "      <td>4.894998e-04</td>\n",
       "      <td>5.407854e-04</td>\n",
       "      <td>3.915998e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Lung area ratio</td>\n",
       "      <td>Q4</td>\n",
       "      <td>42</td>\n",
       "      <td>0.001931</td>\n",
       "      <td>5.407854e-04</td>\n",
       "      <td>5.407854e-04</td>\n",
       "      <td>4.326284e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Lung area ratio</td>\n",
       "      <td>Q5 (large lungs)</td>\n",
       "      <td>43</td>\n",
       "      <td>0.001340</td>\n",
       "      <td>3.794029e-04</td>\n",
       "      <td>5.058705e-04</td>\n",
       "      <td>3.035223e-03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Stratum             Level   N  Mean ΔDice  Wilcoxon p (raw)  \\\n",
       "0       Image area        Q1 (small)  71    0.001658      2.613209e-05   \n",
       "1       Image area       Q2 (medium)  70    0.002421      2.687844e-07   \n",
       "2       Image area        Q3 (large)  71    0.002637      8.679081e-08   \n",
       "3  Lung area ratio  Q1 (small lungs)  43    0.003597      2.603353e-06   \n",
       "4  Lung area ratio                Q2  42    0.002341      6.794283e-06   \n",
       "5  Lung area ratio                Q3  42    0.001969      4.894998e-04   \n",
       "6  Lung area ratio                Q4  42    0.001931      5.407854e-04   \n",
       "7  Lung area ratio  Q5 (large lungs)  43    0.001340      3.794029e-04   \n",
       "\n",
       "     BH q (adj)  Bonferroni p (adj)  \n",
       "0  4.181134e-05        2.090567e-04  \n",
       "1  1.075137e-06        2.150275e-06  \n",
       "2  6.943265e-07        6.943265e-07  \n",
       "3  6.942273e-06        2.082682e-05  \n",
       "4  1.358857e-05        5.435426e-05  \n",
       "5  5.407854e-04        3.915998e-03  \n",
       "6  5.407854e-04        4.326284e-03  \n",
       "7  5.058705e-04        3.035223e-03  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import wilcoxon\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "\n",
    "df = pd.read_csv(\"/Users/t/Documents/DISSERTATION/outputs/bucket_eval/per_image_with_meta.csv\")\n",
    "\n",
    "area_map = {0:'Q1 (small)', 1:'Q2 (medium)', 2:'Q3 (large)'}\n",
    "lung_map = {0:'Q1 (small lungs)',1:'Q2',2:'Q3',3:'Q4',4:'Q5 (large lungs)'}\n",
    "df['area_label'] = df['area_bin'].map(area_map)\n",
    "df['lung_label'] = df['lung_ratio_bin'].map(lung_map)\n",
    "\n",
    "rows = []\n",
    "for k, sub in df.groupby('area_label'):\n",
    "    stat = wilcoxon(sub['delta_dice'], alternative='greater', zero_method='wilcox')\n",
    "    rows.append(['Image area', k, len(sub), sub['delta_dice'].mean(), stat.pvalue])\n",
    "\n",
    "for k, sub in df.groupby('lung_label'):\n",
    "    stat = wilcoxon(sub['delta_dice'], alternative='greater', zero_method='wilcox')\n",
    "    rows.append(['Lung area ratio', k, len(sub), sub['delta_dice'].mean(), stat.pvalue])\n",
    "\n",
    "res = pd.DataFrame(rows, columns=['Stratum','Level','N','Mean ΔDice','Wilcoxon p (raw)'])\n",
    "\n",
    "res['BH q (adj)'] = multipletests(res['Wilcoxon p (raw)'], method='fdr_bh')[1]\n",
    "res['Bonferroni p (adj)'] = multipletests(res['Wilcoxon p (raw)'], method='bonferroni')[1]\n",
    "\n",
    "res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35985f11-f14b-48e9-8e26-571bd73e49b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
